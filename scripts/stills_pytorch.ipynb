{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horse Image Classification with PyTorch\n",
    "# =======================================\n",
    "\n",
    "# Step 1: Import Required Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a Custom Dataset Class\n",
    "class HorseDataset(Dataset):\n",
    "    def __init__(self, metadata_df, transform=None):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['horse_id'] - 1  # Subtract 1 to convert to 0-based index\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the Data\n",
    "def load_and_prepare_data(metadata_df, test_size=0.2, random_state=42):\n",
    "    # Define transformations for images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Split metadata into training and testing sets\n",
    "    train_df, test_df = train_test_split(metadata_df, test_size=test_size, random_state=random_state, stratify=metadata_df['horse_id'])\n",
    "\n",
    "    # Create PyTorch datasets\n",
    "    train_dataset = HorseDataset(train_df, transform=transform)\n",
    "    test_dataset = HorseDataset(test_df, transform=transform)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the Training Loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Prepare data for model training:\n",
    "# Base path to the database\n",
    "base_dir = '../data/THoDBRL2015'\n",
    "\n",
    "metadata = []\n",
    "\n",
    "# Consolidate images into a training directory\n",
    "output_train_dir = os.path.join(base_dir, 'training_data')\n",
    "\n",
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "\n",
    "parts = [\n",
    "    'Part1', \n",
    "    # 'Part2', \n",
    "    # 'Part3', \n",
    "    # 'Part4', \n",
    "    # 'Part5'\n",
    "]\n",
    "\n",
    "# Iterate through each Part folder\n",
    "for part in parts:\n",
    "    videos_dir = os.path.join(base_dir, part, 'videos')\n",
    "\n",
    "    for horse_id_folder in os.listdir(videos_dir):\n",
    "        horse_path = os.path.join(videos_dir, horse_id_folder)\n",
    "\n",
    "        if os.path.isdir(horse_path):  # Ensure it's a directory\n",
    "            # Find all stills folders (e.g., images, images1, images2, etc.)\n",
    "            for stills_folder in os.listdir(horse_path):\n",
    "                stills_path = os.path.join(horse_path, stills_folder)\n",
    "\n",
    "                if os.path.isdir(stills_path) and stills_folder.startswith('images'):  # Check for folders named 'images*'\n",
    "                    target_dir = os.path.join(output_train_dir, f'horse_{horse_id_folder}')\n",
    "\n",
    "                    os.makedirs(target_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Copy all image files from the stills folder to the target directory\n",
    "                    for img_file in os.listdir(stills_path):\n",
    "                        img_path = os.path.join(stills_path, img_file)\n",
    "\n",
    "                        if img_file.endswith(('.jpg', '.jpeg', '.png')):  # Ensure it's an image file\n",
    "                            metadata.append({\n",
    "                                'horse_id': horse_id_folder,\n",
    "                                'image_path': img_path,\n",
    "                                'width': Image.open(img_path).size[0],\n",
    "                                'height': Image.open(img_path).size[1],\n",
    "                            })\n",
    "                        \n",
    "                            # shutil.copy(img_path, target_dir)\n",
    "\n",
    "                    # print(f\"Copied images from {stills_path} to {target_dir}\")\n",
    "\n",
    "# Create DataFrame with specified dtypes\n",
    "metadata_df = pd.DataFrame(metadata, dtype='object').astype({\n",
    "    'horse_id': 'int64',          # Assuming it's an integer\n",
    "    'image_path': 'string',\n",
    "    'width': 'int64',\n",
    "    'height': 'int64',\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load Metadata and Prepare the Dataset\n",
    "# Replace with your actual metadata DataFrame\n",
    "# metadata_df = pd.DataFrame({\n",
    "#     'image_path': ['path_to_image_1.jpg', 'path_to_image_2.jpg'],  # Replace with actual paths\n",
    "#     'horse_id': [0, 1]\n",
    "# })\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "train_dataset, test_dataset = load_and_prepare_data(metadata_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Initialize the Model, Loss Function, and Optimizer\n",
    "num_classes = metadata_df['horse_id'].nunique()\n",
    "print(metadata_df['horse_id'].unique())\n",
    "model = CNNModel(num_classes)\n",
    "\n",
    "# Use Cross-Entropy Loss for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train the Model\n",
    "# Set the device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions and ground truth labels (modify according to your model/data)\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:  # Replace 'test_loader' with your test DataLoader\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classes = range(num_classes)  # Adjust with class names if available\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_horseface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
