{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "\n",
    "from tf_keras.models import Sequential\n",
    "from tf_keras.layers import Conv2D, Input\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 128, 3)),\n",
    "    Conv2D(32, (3,3))\n",
    "])\n",
    "\n",
    "model.summary()  # This will show output shapes.\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(\"Layer name:\", layer.name)\n",
    "    print(\"Output shape:\", layer.output.shape)\n",
    "\n",
    "\n",
    "# grad_model = tf.keras.models.Model(\n",
    "# [model.inputs], [model.get_layer(layer.name).output, model.output]\n",
    "# )\n",
    "# model.inputs\n",
    "# model.outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Load the HDF5 file\n",
    "with h5py.File('model.h5', 'r') as f:\n",
    "    keras_version = f.attrs.get('keras_version')\n",
    "    print(f\"Keras Version: {keras_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(\"conv2d\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.input is None:\n",
    "    print(\"The model is not connected to an input.\")\n",
    "else:\n",
    "    print(f\"Input shape: {model.input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_explain\n",
    "import numpy as np\n",
    "\n",
    "# Import explainer\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# image = np.random.random((1, 28, 28))  # Single grayscale image\n",
    "image = np.random.rand(1, 128, 128, 3).astype(np.float32)\n",
    "\n",
    "label = np.array([1])  # Class label\n",
    "\n",
    "\n",
    "# Instantiation of the explainer\n",
    "explainer = GradCAM()\n",
    "\n",
    "# Call to explain() method\n",
    "output = explainer.explain(model=model, \n",
    "                            layer_name=\"conv2d\", \n",
    "                            class_index=0,\n",
    "                            validation_data=(image, label))\n",
    "\n",
    "# Save output\n",
    "explainer.save(output, \"files\", \"output_name.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_horseface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
