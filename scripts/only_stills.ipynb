{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunisian Horses - Only stills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras: 2.18.0\n",
      "backend: tensorflow\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import tensorflow.keras as keras\n",
    "from tf_keras.utils import to_categorical\n",
    "from tf_keras.models import Sequential\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tf_keras import Input\n",
    "\n",
    "print(f\"keras: {keras.__version__}\")\n",
    "print(f\"backend: {keras.backend.backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Prepare data for model training:\n",
    "# Base path to the database\n",
    "base_dir = '../data/THoDBRL2015'\n",
    "\n",
    "metadata = []\n",
    "\n",
    "# Consolidate images into a training directory\n",
    "output_train_dir = os.path.join(base_dir, 'training_data')\n",
    "\n",
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "\n",
    "parts = [\n",
    "    'Part1', \n",
    "    # 'Part2', \n",
    "    # 'Part3', \n",
    "    # 'Part4', \n",
    "    # 'Part5'\n",
    "]\n",
    "\n",
    "# Iterate through each Part folder\n",
    "for part in parts:\n",
    "    videos_dir = os.path.join(base_dir, part, 'videos')\n",
    "\n",
    "    for horse_id_folder in os.listdir(videos_dir):\n",
    "        horse_path = os.path.join(videos_dir, horse_id_folder)\n",
    "\n",
    "        if os.path.isdir(horse_path):  # Ensure it's a directory\n",
    "            # Find all stills folders (e.g., images, images1, images2, etc.)\n",
    "            for stills_folder in os.listdir(horse_path):\n",
    "                stills_path = os.path.join(horse_path, stills_folder)\n",
    "\n",
    "                if os.path.isdir(stills_path) and stills_folder.startswith('images'):  # Check for folders named 'images*'\n",
    "                    target_dir = os.path.join(output_train_dir, f'horse_{horse_id_folder}')\n",
    "\n",
    "                    os.makedirs(target_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Copy all image files from the stills folder to the target directory\n",
    "                    for img_file in os.listdir(stills_path):\n",
    "                        img_path = os.path.join(stills_path, img_file)\n",
    "\n",
    "                        if img_file.endswith(('.jpg', '.jpeg', '.png')):  # Ensure it's an image file\n",
    "                            metadata.append({\n",
    "                                'horse_id': horse_id_folder,\n",
    "                                'image_path': img_path,\n",
    "                                'width': Image.open(img_path).size[0],\n",
    "                                'height': Image.open(img_path).size[1],\n",
    "                            })\n",
    "                        \n",
    "                            # shutil.copy(img_path, target_dir)\n",
    "\n",
    "                    # print(f\"Copied images from {stills_path} to {target_dir}\")\n",
    "\n",
    "# Create DataFrame with specified dtypes\n",
    "metadata_df = pd.DataFrame(metadata, dtype='object').astype({\n",
    "    'horse_id': 'int64',          # Assuming it's an integer\n",
    "    'image_path': 'string',\n",
    "    'width': 'int64',\n",
    "    'height': 'int64',\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10364\n",
      "Total horses: 10\n",
      "Width: [640]\n",
      "Height: [480]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total images: {len(metadata_df)}\")\n",
    "print(f\"Total horses: {metadata_df['horse_id'].nunique()}\")\n",
    "print(f\"Width: {metadata_df['width'].unique()}\")\n",
    "print(f\"Height: {metadata_df['height'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   horse_id                                         image_path  width  height\n",
      "0         9  ../data/THoDBRL2015/Part1/videos/9/images1/img...    640     480\n",
      "1         9  ../data/THoDBRL2015/Part1/videos/9/images1/img...    640     480\n",
      "2         9  ../data/THoDBRL2015/Part1/videos/9/images1/img...    640     480\n",
      "3         9  ../data/THoDBRL2015/Part1/videos/9/images1/img...    640     480\n",
      "4         9  ../data/THoDBRL2015/Part1/videos/9/images1/img...    640     480\n"
     ]
    }
   ],
   "source": [
    "print(metadata_df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">width</th>\n",
       "      <th colspan=\"8\" halign=\"left\">height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1415.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1282.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1173.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>548.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>729.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1226.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1262.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>585.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1115.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           width                                                 height  \\\n",
       "           count   mean  std    min    25%    50%    75%    max   count   \n",
       "horse_id                                                                  \n",
       "1         1415.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1415.0   \n",
       "2         1029.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1029.0   \n",
       "3         1282.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1282.0   \n",
       "4         1173.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1173.0   \n",
       "5          548.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0   548.0   \n",
       "6          729.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0   729.0   \n",
       "7         1226.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1226.0   \n",
       "8         1262.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1262.0   \n",
       "9          585.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0   585.0   \n",
       "10        1115.0  640.0  0.0  640.0  640.0  640.0  640.0  640.0  1115.0   \n",
       "\n",
       "                                                         \n",
       "           mean  std    min    25%    50%    75%    max  \n",
       "horse_id                                                 \n",
       "1         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "2         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "3         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "4         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "5         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "6         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "7         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "8         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "9         480.0  0.0  480.0  480.0  480.0  480.0  480.0  \n",
       "10        480.0  0.0  480.0  480.0  480.0  480.0  480.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_horse = metadata_df.groupby(['horse_id'], observed=True)\n",
    "\n",
    "grouped_horse.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min      548.0\n",
       "max     1415.0\n",
       "mean    1036.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Images per horse id\n",
    "grouped_horse.size().agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For splitting data\n",
    "# Load data\n",
    "# Prepare dataset\n",
    "def load_images_and_labels(metadata_df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    resize_value = (128, 128)\n",
    "    # resize_value = (224, 224) # ResNet50 default input size\n",
    "\n",
    "    \n",
    "    for _, row in metadata_df.iterrows():\n",
    "        if os.path.exists(row['image_path']):\n",
    "            img = Image.open(row['image_path']).resize(resize_value)  # Scale to same size\n",
    "            images.append(np.array(img))\n",
    "            labels.append(row['horse_id'])  # use horse_id for the label\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "images, labels = load_images_and_labels(metadata_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split into Temporary (Train + Validation) and Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Temporary (Train + Validation) into Train and Validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6632, 128, 128, 3),\n",
       " (1659, 128, 128, 3),\n",
       " (2073, 128, 128, 3),\n",
       " (6632,),\n",
       " (1659,),\n",
       " (2073,))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validation.shape, X_test.shape, y_train.shape, y_validation.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise pixelvalues\n",
    "# X_train = X_train / 255.0\n",
    "# X_test = X_test / 255.0\n",
    "\n",
    "# Transfer labels to category data\n",
    "# num_classes = len(metadata_df['horse_id'].unique())\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# 0-based index\n",
    "y_train = y_train - 1  # If needed then custumize labels (sometimes gives error)\n",
    "y_test = y_test - 1  # The same for test\n",
    "y_validation = y_validation - 1  # The same for validation\n",
    "\n",
    "# print(y_train.min())  # Min label value\n",
    "# print(y_train.max())  # Max label value\n",
    "\n",
    "# Convert labels to categorical data\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_validation = to_categorical(y_validation, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise pixel values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN: Sequential Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_custom_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    # INPUT_SHAPE = (224, 224, 3) # Default for ResNet50\n",
    "\n",
    "    # Add layers step-by-step\n",
    "    # model.add(Input(shape=INPUT_SHAPE))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # To prevent overfitting\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Output layer\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_model():\n",
    "    INPUT_SHAPE = (128, 128, 3)\n",
    "    model = keras.applications.ResNet50(\n",
    "        include_top=True, weights=None, input_tensor=None, input_shape=INPUT_SHAPE,\n",
    "        pooling=None, classes=num_classes\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 134, 134, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 64, 64, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 64, 64, 64)           256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 64, 64, 64)           0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 66, 66, 64)           0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 32, 32, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 32, 32, 64)           4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 32, 32, 256)          16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 32, 32, 256)          0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 32, 32, 256)          0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 32, 32, 256)          0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 32, 32, 256)          0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 16, 16, 128)          32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 16, 16, 512)          131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 16, 16, 512)          0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 16, 16, 512)          0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 16, 16, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 16, 16, 512)          0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 16, 16, 512)          0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 16, 16, 512)          0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 8, 8, 256)            131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 8, 8, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " predictions (Dense)         (None, 10)                   20490     ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23608202 (90.06 MB)\n",
      "Trainable params: 23555082 (89.86 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "# model = create_custom_model()\n",
    "model = create_resnet_model()\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "# Sequential model: No “connected to” column. The model is linearly connected layer by layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thijs/fontys/dasc2/HorseFace/venv_horseface/lib/python3.12/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "import h5py\n",
    "\n",
    "# Load the HDF5 file\n",
    "with h5py.File('model.h5', 'r') as f:\n",
    "    keras_version = f.attrs.get('keras_version')\n",
    "    print(f\"Keras Version: {keras_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6632, 10)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "# y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 470s 2s/step - loss: 0.3465 - accuracy: 0.9012 - val_loss: 4.8256 - val_accuracy: 0.3900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_validation, y_validation)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings with epochs=10 and batch_size=32\n",
    "- expected time (335 sec * 10 epochs) ~~ 1 hour\n",
    "- Accuracy in 1st epoch: 0.54, and loss 3.92\n",
    "- Accuracy in 2nd epoch: on the start already accuracy of 0.91\n",
    "- In 2nd epoch, no big changes.\n",
    "\n",
    "Findings with epochs=1 and batch_size=64\n",
    "- expected time ~6 min (so same time per epoch)\n",
    "- accuracy is >0.95.\n",
    "\n",
    "Explanation:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a `.keras` zip archive.\n",
    "model.save('../data/saved_models/my_model_epoch_1_batch_size_128.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 28s 421ms/step - loss: 4.8271 - accuracy: 0.3874\n",
      "Test Loss: 4.827070236206055\n",
      "Test Accuracy: 0.3873613178730011\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 128, 128, 3)\n",
      "65/65 [==============================] - 28s 429ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [str(i) for i in range(metadata_df['horse_id'].nunique())]  \n",
    "\n",
    "# predict the labels for testset\n",
    "print(X_test.shape)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "# Plot The confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Real Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM\n",
    "GradCAM = Gradient-Weighted Class Activation Mapping\n",
    "\n",
    "Use GradCAM to visualize the areas of the image that the model is looking at when making predictions.\n",
    "We use the last convolutional layer of the model as the last layer before the output layer.\n",
    "We use `tf-explain` to generate the GradCAM heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model or your own\n",
    "# model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=True)\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "if model.input is None:\n",
    "    print(\"The model is not connected to an input.\")\n",
    "else:\n",
    "    print(f\"Input shape: {model.input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer model input shape: (None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Outer model input shape: {model.input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is connected to an input.\n"
     ]
    }
   ],
   "source": [
    "if model.built:\n",
    "    print(\"The model is connected to an input.\")\n",
    "else:\n",
    "    print(\"The model is not connected to an input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer input_2 is connected with output shape (None, 128, 128, 3)\n",
      "Layer conv1_pad is connected with output shape (None, 134, 134, 3)\n",
      "Layer conv1_conv is connected with output shape (None, 64, 64, 64)\n",
      "Layer conv1_bn is connected with output shape (None, 64, 64, 64)\n",
      "Layer conv1_relu is connected with output shape (None, 64, 64, 64)\n",
      "Layer pool1_pad is connected with output shape (None, 66, 66, 64)\n",
      "Layer pool1_pool is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_1_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_1_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_1_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_2_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_2_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_2_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block1_0_conv is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block1_3_conv is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block1_0_bn is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block1_3_bn is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block1_add is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block1_out is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block2_1_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_1_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_1_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_2_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_2_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_2_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block2_3_conv is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block2_3_bn is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block2_add is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block2_out is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block3_1_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_1_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_1_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_2_conv is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_2_bn is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_2_relu is connected with output shape (None, 32, 32, 64)\n",
      "Layer conv2_block3_3_conv is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block3_3_bn is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block3_add is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv2_block3_out is connected with output shape (None, 32, 32, 256)\n",
      "Layer conv3_block1_1_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_1_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_1_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_2_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_2_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_2_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block1_0_conv is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block1_3_conv is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block1_0_bn is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block1_3_bn is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block1_add is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block1_out is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block2_1_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_1_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_1_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_2_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_2_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_2_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block2_3_conv is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block2_3_bn is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block2_add is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block2_out is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block3_1_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_1_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_1_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_2_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_2_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_2_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block3_3_conv is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block3_3_bn is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block3_add is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block3_out is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block4_1_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_1_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_1_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_2_conv is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_2_bn is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_2_relu is connected with output shape (None, 16, 16, 128)\n",
      "Layer conv3_block4_3_conv is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block4_3_bn is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block4_add is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv3_block4_out is connected with output shape (None, 16, 16, 512)\n",
      "Layer conv4_block1_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block1_0_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block1_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block1_0_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block1_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block1_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block1_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block2_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block2_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block2_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block2_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block2_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block3_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block3_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block3_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block3_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block3_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block4_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block4_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block4_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block4_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block4_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block5_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block5_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block5_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block5_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block5_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block6_1_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_1_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_1_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_2_conv is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_2_bn is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_2_relu is connected with output shape (None, 8, 8, 256)\n",
      "Layer conv4_block6_3_conv is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block6_3_bn is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block6_add is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv4_block6_out is connected with output shape (None, 8, 8, 1024)\n",
      "Layer conv5_block1_1_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_1_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_1_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_2_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_2_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_2_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block1_0_conv is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block1_3_conv is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block1_0_bn is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block1_3_bn is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block1_add is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block1_out is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block2_1_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_1_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_1_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_2_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_2_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_2_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block2_3_conv is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block2_3_bn is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block2_add is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block2_out is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block3_1_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_1_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_1_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_2_conv is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_2_bn is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_2_relu is connected with output shape (None, 4, 4, 512)\n",
      "Layer conv5_block3_3_conv is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block3_3_bn is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block3_add is connected with output shape (None, 4, 4, 2048)\n",
      "Layer conv5_block3_out is connected with output shape (None, 4, 4, 2048)\n",
      "Layer avg_pool is connected with output shape (None, 2048)\n",
      "Layer predictions is connected with output shape (None, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'output'):\n",
    "        print(f\"Layer {layer.name} is connected with output shape {layer.output.shape}\")\n",
    "    else:\n",
    "        print(f\"Layer {layer.name} is not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 3)\n",
      "(None, 134, 134, 3)\n",
      "(None, 64, 64, 64)\n",
      "(None, 64, 64, 64)\n",
      "(None, 64, 64, 64)\n",
      "(None, 66, 66, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 64)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 32, 32, 256)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 128)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 256)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 8, 8, 1024)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 512)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 4, 4, 2048)\n",
      "(None, 2048)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_grad_cam_target_layer_modified(model):\n",
    "        \"\"\"\n",
    "        Search for the last convolutional layer to perform Grad CAM, as stated\n",
    "        in the original paper.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "\n",
    "        Returns:\n",
    "            str: Name of the target layer\n",
    "        \"\"\"\n",
    "        for layer in reversed(model.layers):\n",
    "            # Select closest 4D layer to the end of the network.\n",
    "            if len(layer.output.shape) == 4:\n",
    "                return layer.name\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Model does not seem to contain 4D layer. Grad CAM cannot be applied.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target layer: conv5_block3_out\n",
      "model inputs shape: [<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'input_2')>]\n",
      "KerasTensor: <KerasTensor shape=(None, 128, 128, 3), dtype=float32, sparse=False, name=keras_tensor_814>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All `inputs` values must be KerasTensors. Received: inputs=[[<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'input_2')>]] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m KerasTensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasTensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mKerasTensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_DATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLAYER_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fontys/dasc2/HorseFace/venv_horseface/lib/python3.12/site-packages/tf_explain/core/grad_cam.py:54\u001b[0m, in \u001b[0;36mGradCAM.explain\u001b[0;34m(self, validation_data, model, class_index, layer_name, use_guided_grads, colormap, image_weight)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer_grad_cam_target_layer(model)\n\u001b[0;32m---> 54\u001b[0m outputs, grads \u001b[38;5;241m=\u001b[39m \u001b[43mGradCAM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gradients_and_filters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_guided_grads\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m cams \u001b[38;5;241m=\u001b[39m GradCAM\u001b[38;5;241m.\u001b[39mgenerate_ponderated_output(outputs, grads)\n\u001b[1;32m     60\u001b[0m heatmaps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     61\u001b[0m     [\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# not showing the actual image if image_weight=0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     ]\n\u001b[1;32m     66\u001b[0m )\n",
      "File \u001b[0;32m~/fontys/dasc2/HorseFace/venv_horseface/lib/python3.12/site-packages/tf_explain/core/grad_cam.py:110\u001b[0m, in \u001b[0;36mGradCAM.get_gradients_and_filters\u001b[0;34m(model, images, layer_name, class_index, use_guided_grads)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gradients_and_filters\u001b[39m(\n\u001b[1;32m     95\u001b[0m     model, images, layer_name, class_index, use_guided_grads\n\u001b[1;32m     96\u001b[0m ):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Generate guided gradients and convolutional outputs with an inference.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        Tuple[tf.Tensor, tf.Tensor]: (Target layer outputs, Guided gradients)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     grad_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    115\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(images, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/fontys/dasc2/HorseFace/venv_horseface/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/fontys/dasc2/HorseFace/venv_horseface/lib/python3.12/site-packages/keras/src/models/functional.py:119\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All `inputs` values must be KerasTensors. Received: inputs=[[<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'input_2')>]] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "image = np.random.random((1, 28, 28))  # Single grayscale image\n",
    "label = np.array([1])  # Class label\n",
    "\n",
    "target_layer = infer_grad_cam_target_layer_modified(model)\n",
    "print(f\"Target layer: {target_layer}\")\n",
    "\n",
    "# LAYER_NAME = \"conv5_block3_3_conv\" # The last convolutional layer\n",
    "LAYER_NAME = \"conv2_block1_1_conv\" # The last convolutional layer\n",
    "\n",
    "# Grad-CAM visualization\n",
    "explainer = GradCAM()\n",
    "# required positional arguments: 'validation_data', 'model', and 'class_index'\n",
    "# layer_name is optional: tf-learn selects closest 4D layer to the end of the network. ACHTUNG: tf-learn has compatibility issues with tf2.0\n",
    "VALIDATION_DATA = (image, label)\n",
    "\n",
    "print(f\"model inputs shape: {model.inputs}\")\n",
    "KerasTensor = tf.keras.Input(shape=(128, 128, 3))\n",
    "print(f\"KerasTensor: {KerasTensor}\")\n",
    "grid = explainer.explain(validation_data=VALIDATION_DATA, model=model, class_index=10, layer_name=LAYER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error 30 December when using custom-model:\n",
    "\n",
    "ValueError: All `inputs` values must be KerasTensors. Received: inputs=[[<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'conv2d_3_input')>]] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='conv2d_3_input'), name='conv2d_3_input', description=\"created by layer 'conv2d_3_input'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming df is already defined and contains the image paths\n",
    "IMAGE_PATH = df['image_path'][300]\n",
    "\n",
    "\n",
    "# Load a sample image (or multiple ones)\n",
    "img = keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(128, 128))\n",
    "img = keras.preprocessing.image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)  # Expand to 4D tensor\n",
    "img = img / 255.0  # Normalize if required\n",
    "\n",
    "# Ensure the model is called with input data\n",
    "prediction = model.predict(img)\n",
    "class_index = np.argmax(prediction, axis=1)[0]  # Get the predicted class\n",
    "\n",
    "# Prepare data for GradCAM\n",
    "data = (img, None)\n",
    "\n",
    "# Start explainer\n",
    "explainer = GradCAM()\n",
    "grid = explainer.explain(data, model, class_index=class_index, layer_name=LAYER_NAME)\n",
    "\n",
    "# Save the GradCAM result\n",
    "explainer.save(grid, \".\", \"grad_cam.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error when using custom model:\n",
    "AttributeError: The layer sequential_2 has never been called and thus has no defined output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the original image for overlay\n",
    "original_img = Image.open(IMAGE_PATH).resize((128, 128))\n",
    "\n",
    "# Create a heatmap from GradCAM output\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"GradCAM Heatmap\")\n",
    "plt.imshow(grid, cmap='jet')\n",
    "plt.axis('off')\n",
    "\n",
    "# Overlay heatmap on the original image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Overlayed Heatmap\")\n",
    "plt.imshow(original_img)\n",
    "plt.imshow(grid, cmap='jet', alpha=0.5)  # Adjust alpha for transparency\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the results\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_horseface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
