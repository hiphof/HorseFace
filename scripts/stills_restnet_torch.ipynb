{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horse Image Classification with PyTorch\n",
    "# =======================================\n",
    "\n",
    "# Step 1: Import Required Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseDataset(Dataset):\n",
    "    def __init__(self, metadata_df, transform=None):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['horse_id'] - 1  # Subtract 1 to convert to 0-based index\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(metadata_df, test_size=0.2, random_state=42):\n",
    "    # Define transformations for images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Split metadata into training and testing sets\n",
    "    train_df, test_df = train_test_split(metadata_df, test_size=test_size, random_state=random_state, stratify=metadata_df['horse_id'])\n",
    "\n",
    "    # Create PyTorch datasets\n",
    "    train_dataset = HorseDataset(train_df, transform=transform)\n",
    "    test_dataset = HorseDataset(test_df, transform=transform)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Define the Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.train()  # Ensure model is in training mode\n",
    "\n",
    "    # Add the parameter check here\n",
    "    print(\"Checking model parameters for requires_grad:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name}, requires_grad: {param.requires_grad}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Ensure requires_grad is enabled for the input\n",
    "            images.requires_grad_(True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Check for gradient flow\n",
    "            assert loss.requires_grad, \"Loss tensor does not require gradient.\"\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data for model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base path to the database\n",
    "base_dir = '../data/THoDBRL2015'\n",
    "\n",
    "metadata = []\n",
    "\n",
    "# Consolidate images into a training directory\n",
    "output_train_dir = os.path.join(base_dir, 'training_data')\n",
    "\n",
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "\n",
    "parts = [\n",
    "    'Part1', \n",
    "    # 'Part2', \n",
    "    # 'Part3', \n",
    "    # 'Part4', \n",
    "    # 'Part5'\n",
    "]\n",
    "\n",
    "# Iterate through each Part folder\n",
    "for part in parts:\n",
    "    videos_dir = os.path.join(base_dir, part, 'videos')\n",
    "\n",
    "    for horse_id_folder in os.listdir(videos_dir):\n",
    "        horse_path = os.path.join(videos_dir, horse_id_folder)\n",
    "\n",
    "        if os.path.isdir(horse_path):  # Ensure it's a directory\n",
    "            # Find all stills folders (e.g., images, images1, images2, etc.)\n",
    "            for stills_folder in os.listdir(horse_path):\n",
    "                stills_path = os.path.join(horse_path, stills_folder)\n",
    "\n",
    "                if os.path.isdir(stills_path) and stills_folder.startswith('images'):  # Check for folders named 'images*'\n",
    "                    target_dir = os.path.join(output_train_dir, f'horse_{horse_id_folder}')\n",
    "\n",
    "                    os.makedirs(target_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Copy all image files from the stills folder to the target directory\n",
    "                    for img_file in os.listdir(stills_path):\n",
    "                        img_path = os.path.join(stills_path, img_file)\n",
    "\n",
    "                        if img_file.endswith(('.jpg', '.jpeg', '.png')):  # Ensure it's an image file\n",
    "                            metadata.append({\n",
    "                                'horse_id': horse_id_folder,\n",
    "                                'image_path': img_path,\n",
    "                                'width': Image.open(img_path).size[0],\n",
    "                                'height': Image.open(img_path).size[1],\n",
    "                            })\n",
    "                        \n",
    "                            # shutil.copy(img_path, target_dir)\n",
    "\n",
    "                    # print(f\"Copied images from {stills_path} to {target_dir}\")\n",
    "\n",
    "# Create DataFrame with specified dtypes\n",
    "metadata_df = pd.DataFrame(metadata, dtype='object').astype({\n",
    "    'horse_id': 'int64',          # Assuming it's an integer\n",
    "    'image_path': 'string',\n",
    "    'width': 'int64',\n",
    "    'height': 'int64',\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Load Metadata and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual metadata DataFrame\n",
    "# metadata_df = pd.DataFrame({\n",
    "#     'image_path': ['path_to_image_1.jpg', 'path_to_image_2.jpg'],  # Replace with actual paths\n",
    "#     'horse_id': [0, 1]\n",
    "# })\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "train_dataset, test_dataset = load_and_prepare_data(metadata_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Initialize the Model, Loss Function, and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "num_classes = metadata_df['horse_id'].nunique()\n",
    "print(metadata_df['horse_id'].unique())\n",
    "model = resnet18(pretrained=False).eval()\n",
    "# model = CNNModel(num_classes)\n",
    "\n",
    "# Use Cross-Entropy Loss for classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "1 epoch takes 5 minutes on Macbook M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate predictions and ground truth labels (modify according to your model/data)\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:  # Replace 'test_loader' with your test DataLoader\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        print(f\"Outputs requires_grad: {outputs.requires_grad}\")  # Debugging\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classes = range(num_classes)  # Adjust with class names if available\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval() # Already done while creating Confusion Matrix\n",
    "\n",
    "# Set your CAM extractor\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "cam_extractor = SmoothGradCAMpp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING:root:no value was provided for `target_layer`, thus set to 'layer4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "\n",
    "# model = resnet18(pretrained=True).eval()\n",
    "\n",
    "# Get your input\n",
    "img = read_image(\"../data/internet/test_horse_internet.jpg\")\n",
    "\n",
    "\n",
    "# Preprocess it for your chosen model\n",
    "input_tensor = normalize(resize(img, (224, 224)) / 255., [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "input_tensor.requires_grad_(True)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "\n",
    "with SmoothGradCAMpp(model) as cam_extractor:\n",
    "  # Preprocess your data and feed it to the model\n",
    "  out = model(input_tensor.unsqueeze(0))\n",
    "  # Retrieve the CAM by passing the class index and the model output\n",
    "  activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: cannot register a hook on a tensor that doesn't require gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no explicit .register_hook or related hook operations in the notebook. However, the error can also arise indirectly during gradient computations or when calling .backward().\n",
    "\n",
    "To debug further:\n",
    "\t1.\tEnsure inputs and outputs: Confirm that tensors involved in .backward() have requires_grad=True.\n",
    "\t2.\tVerify model parameters: All model parameters should have requires_grad=True unless explicitly frozen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_horseface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
