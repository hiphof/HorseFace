{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "182017a7beaf8232",
   "metadata": {},
   "source": [
    "# Tunisian Horses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcccfc025ec706d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.493061Z",
     "start_time": "2024-11-19T12:05:27.574667Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# Set the path to the main directory containing the folders of images\n",
    "main_dir = '../data/THoDBRL2015'\n",
    "search_in_dir = 'Croped Images'\n",
    "\n",
    "# Initialize a list to hold metadata\n",
    "metadata = []\n",
    "\n",
    "# Recursively walk through each folder and subfolder to collect metadata\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    # 'root' is the current directory in the hierarchy\n",
    "    # 'dirs' are the directories in 'root'\n",
    "    # 'files' are the files in 'root'\n",
    "    # basename = os.path.basename(root)\n",
    "    if search_in_dir in root:\n",
    "        for filename in files:\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):  # Adjust extensions as needed\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Extract the folder name as the relative path from main_dir to the current folder\n",
    "                relative_folder_path = os.path.relpath(root, main_dir)\n",
    "\n",
    "                match_horse_id = re.search(r'\\d+$', relative_folder_path)\n",
    "                horse_id = match_horse_id.group() if match_horse_id else None  # Assign None if no match is found\n",
    "\n",
    "                # Determine category based on filename content\n",
    "                if 'Dhr' in filename: # Droit\n",
    "                    camera_position_category = 'Right'\n",
    "                elif 'Ghr' in filename: # Gauche\n",
    "                    camera_position_category = 'Left'\n",
    "                elif 'fhr' in filename: # front\n",
    "                    camera_position_category = 'Front'\n",
    "                else:\n",
    "                    camera_position_category = 'Unknown'\n",
    "\n",
    "                match_position = re.sub(r'\\d', '', filename)\n",
    "                # camera_position = match_position.group() if match_position else None\n",
    "\n",
    "                with Image.open(main_dir + '/' + relative_folder_path + '/' + filename) as img:\n",
    "                    width, height = img.size  # .size returns (width, height)\n",
    "\n",
    "                # Determine orientation\n",
    "                if width > height:\n",
    "                    orientations = 'Landscape'\n",
    "                elif height > width:\n",
    "                    orientation = 'Portrait'\n",
    "                else:\n",
    "                    orientation = 'Square'\n",
    "\n",
    "\n",
    "                # Add metadata: Folder path, filename, and full file path\n",
    "                metadata.append({\n",
    "                    'file_path': file_path,\n",
    "                    'horse_id': horse_id,\n",
    "                    'photo_id': re.search(r'\\d+', filename).group(),\n",
    "                    'folder': relative_folder_path,  # This will give the relative path of the folder structure\n",
    "                    'filename': filename,\n",
    "                    'format': filename.split('.')[-1],\n",
    "                    'camera_position': camera_position_category,\n",
    "                    'file_size': os.path.getsize(file_path),\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'aspect_ratio': width / height,\n",
    "                    'orientation': orientation,\n",
    "                })\n",
    "\n",
    "# Create DataFrame with specified dtypes\n",
    "metadata_df = pd.DataFrame(metadata, dtype='object').astype({\n",
    "    'file_path': 'string',\n",
    "    'horse_id': 'int64',          # Assuming it's an integer\n",
    "    'photo_id': 'int64',          # Assuming it's an integer\n",
    "    'folder': 'string',\n",
    "    'filename': 'string',\n",
    "    'format': 'category',        # Categorical for file format\n",
    "    'camera_position': 'category', # Categorical for camera position\n",
    "    'file_size': 'int64',         # Integer for file size in bytes\n",
    "    'width': 'int64',             # Integer for width\n",
    "    'height': 'int64',             # Integer for height\n",
    "    'aspect_ratio': 'float',\n",
    "    'orientation': 'category',\n",
    "})\n",
    "# Convert metadata list to a DataFrame\n",
    "# metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda889dd1657ba13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.520693Z",
     "start_time": "2024-11-19T12:05:28.517361Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df['horse_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480b3a2c48212a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.562056Z",
     "start_time": "2024-11-19T12:05:28.558269Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9f0c7d52c43ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.705653Z",
     "start_time": "2024-11-19T12:05:28.702947Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc12acc6afd91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.777347Z",
     "start_time": "2024-11-19T12:05:28.772293Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df['camera_position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3877b98a070078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.846833Z",
     "start_time": "2024-11-19T12:05:28.843339Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df['aspect_ratio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930d26a22cec289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.951308Z",
     "start_time": "2024-11-19T12:05:28.948476Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_df['orientation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d76d2355bd4803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:28.974158Z",
     "start_time": "2024-11-19T12:05:28.967013Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_horse_camera = metadata_df.groupby(['horse_id', 'camera_position'], observed=True)\n",
    "grouped_horse_camera.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6c42ca9afbed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:29.001539Z",
     "start_time": "2024-11-19T12:05:28.997932Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_horse_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6312895ebfd8e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:29.055498Z",
     "start_time": "2024-11-19T12:05:29.045694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply different aggregations for each column\n",
    "agg_df = grouped_horse_camera.agg({\n",
    "    'file_size': ['min', 'max'],\n",
    "     # 'file_size': 'max'\n",
    "    'aspect_ratio': 'max',\n",
    "    # 'brightness': ['min', 'max']  # Min and max of brightness\n",
    "})\n",
    "print(\"Aggregated DataFrame with multiple functions:\")\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11648e3325a975e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:29.141544Z",
     "start_time": "2024-11-19T12:05:29.132907Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_horse = metadata_df.groupby(['horse_id'], observed=True)\n",
    "agg_horse_df = grouped_horse.agg({\n",
    "    'file_size': ['min', 'max', 'mean', 'std'],\n",
    "})\n",
    "agg_horse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7374ec2a3fef6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:29.186888Z",
     "start_time": "2024-11-19T12:05:29.178936Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_camera_position = metadata_df.groupby(['camera_position'], observed=True)\n",
    "agg_camera_position_df = grouped_camera_position.agg({\n",
    "    'file_size': ['min', 'max', 'mean', 'std'],\n",
    "    'width': ['min', 'max', 'mean'],\n",
    "    'height': ['min', 'max', 'mean'],\n",
    "})\n",
    "agg_camera_position_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c5c4e4ab8a73f",
   "metadata": {},
   "source": [
    "So, all the Front images are 160x380. The Left and Right images are 165x260."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e38f7a8629c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:05:30.804360Z",
     "start_time": "2024-11-19T12:05:29.279549Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Retain only relevant columns for displaying images by horse ID\n",
    "data = metadata_df[['horse_id', 'file_path']]\n",
    "\n",
    "\n",
    "# Drop duplicates to get one image per horse\n",
    "data_unique_horses = data.drop_duplicates(subset=['horse_id'])\n",
    "\n",
    "# Set grid size to display 47 images (8 columns, 6 rows)\n",
    "cols, rows = 8, 6\n",
    "\n",
    "# Create a figure with a static grid of subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 15), dpi=100)  # Set DPI for higher resolution\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Display each selected image\n",
    "for i, (idx, row) in enumerate(data_unique_horses.iterrows()):\n",
    "    img_path = row['file_path']\n",
    "\n",
    "    # Check if the file path is valid before loading\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Ensure RGB mode\n",
    "        axes[i].imshow(img, interpolation='nearest')  # Avoid interpolation\n",
    "    else:\n",
    "        # Display a placeholder text if image path is invalid\n",
    "        axes[i].text(0.5, 0.5, \"Image Not Found\", ha='center', va='center', color=\"red\")\n",
    "\n",
    "    # Hide axes and set title as horse ID\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Horse ID: {row['horse_id']}\")\n",
    "\n",
    "# Hide any remaining empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7fbb12ab380ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:21:37.859872Z",
     "start_time": "2024-11-19T12:21:37.472407Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f88bcad750a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:24:18.469406Z",
     "start_time": "2024-11-19T12:24:18.103674Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe09b1263a75839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:23:11.581806Z",
     "start_time": "2024-11-19T12:23:11.175025Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bff5bbf78a8140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:26:58.522288Z",
     "start_time": "2024-11-19T12:26:58.508398Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3fcaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:21:07.258162Z",
     "start_time": "2024-11-19T12:21:00.119069Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(y_train.max())  # Max label value\n",
    "num_classes = len(metadata_df['horse_id'].unique())\n",
    "print(num_classes)  # Check number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare dataset\n",
    "def load_images_and_labels(metadata_df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in metadata_df.iterrows():\n",
    "        if os.path.exists(row['file_path']):\n",
    "            img = Image.open(row['file_path']).resize((128, 128))  # Scale to same size\n",
    "            images.append(np.array(img))\n",
    "            labels.append(row['horse_id'])  # use horse_id for the label\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Load data\n",
    "images, labels = load_images_and_labels(metadata_df)\n",
    "\n",
    "# Split in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalise pixelvalues\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Transfer labels to category data\n",
    "num_classes = len(metadata_df['horse_id'].unique())\n",
    "#y_train = y_train - 1  # If needed then custumize labels (sometimes gives error)\n",
    "#y_test = y_test - 1  # The same for test\n",
    "\n",
    "# Convert labels to categorical data\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(num_classes, activation='softmax')  # Outputlayer\n",
    "])\n",
    "\n",
    "# Add layers step-by-step\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # To prevent overfitting\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Output layer\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeloverview\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aff329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('horse_identifier_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the model\n",
    "model = load_model('horse_identifier_cnn.h5')\n",
    "\n",
    "# Classify a new imagae\n",
    "def classify_image(img_path):\n",
    "    img = Image.open(img_path).resize((128, 128))\n",
    "    img_array = np.array(img) / 255.0  # Normalise\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # add a batch dimension\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class\n",
    "\n",
    "new_image_path = \"Testfotos Paard.jpg\" #random photo of horse from internet\n",
    "predicted_horse = classify_image(new_image_path)\n",
    "print(f\"Predicted Horse ID: {predicted_horse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab575cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluate Model on testset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# print the results\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70177a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [str(i) for i in range(num_classes)]  \n",
    "\n",
    "# predict the labels for testset\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "# Plot The confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Real Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_horseface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
